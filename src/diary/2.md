
# Safety, Security, Usable Safety (22.04.2021)
In diesem Abschnitt wird hauptsächlich über den Begriff Usable Safety Engineering geredet. Es lohnt sich zu diesem Abschnitt auch ein Blick zu den Modulen Softwareergonomie, Prozessführungssysteme und Ingenieurspsychologie reinzuwerfen.

## Safety
::: tip Safety
- Schutz vor und Erkennung von (unbeabsichtigten) Systemfehlern
- Abfangen resultierender negativer Folgen
:::

## Security
::: tip Security
- Schutz vor und Erkennung von bewusst schädlichem Handeln durch Menschen
- Abfangen resultierender negativer Folgen
:::

## Usable Safety Engineering
::: danger Unklar
Beschäftigt man sich hier nur mit den Fehlern die technisch ausgelöst werden?
:::

Ursprünglich war der Ansatz in den Ingenierswissenschaften, die Steuerungs-, Regelungs- und Automatisierungstechnik zu optimieren, mit dem Ziel der vollständigen Automatisierung. Mittlerweile stehen die komplexen Aufgaben der Operateure im Vordergrund. Ziel ist nun eine Intelligente Mensch-Maschine-Arbeitsteilung zu ermöglichen. Dazu gehört z.B. eine `[b]esondere Sorgfalt und Ausstattung mit Schutzmechanismen und Hinweisen
gegen menschliche oder technische Fehlfunktionen [...]` [(Herczeg, 2008)](/references/#herczeg-m-2008).

::: warning Kommentar
Der Ansatz veränderte sich vermutlich, weil eine Automatisierung auch mit einer Veränderung des Workloads einhergeht und die Wartung des Systems weiterhin vom Menschen durchgeführt werden muss und somit auch an ihm angepasst werden muss und nicht umgekehrt. Es entstehen neue Aufgaben, die gut kalibriertes workload aufzeigen müssen, um nicht zu monoton zu werden oder auch nicht Überanstrengung zu verursachen. Bei beiden Fällen können sonst Fehler vorkommen. Gerade in sicherheitskritischen Systemen ist eine gute Balance in Mensch-Maschine-Systemen zu finden also wichtig (Weitere gute punkte findet man unter dem Begriff Ironies of Automation).
:::

### Begriffe
#### Absolute Sicherheit
::: tip Absolute Sicherheit
Gegeben, wenn keine Wahrscheinlichkeit einer Gefahr besteh, d. h. das
Risiko für diese Gefahr bei 0% liegt.
:::

::: warning Kommentar
Ist absolute Sicherheit jemals möglich?
:::

#### Gefahr
::: tip Gefahr
- Eine Gefahr ist gegeben, wenn die Möglichkeit besteht, dass jemandem
etwas zustößt oder ein Schaden eintritt
- Sie beschreibt den Umfang des Schadens oder der Beeinträchtigung
:::

#### Risiko
::: tip Risiko
Risiko
Produkt der Wahrscheinlichkeit für das Eintreten eines Ereignisses und
der aus ihm resultierenden Gefahr.
:::

### Analyse
> In der Analysephase müssen die spezifischen Fähigkeiten und Grenzen von Mensch und Technik im Anwendungskontext für die Konzeption der Arbeitsteilung erarbeitet werden. [(Herczeg, 2008)](/references/#herczeg-m-2008)

- Recherche in wissenschaftlicher Literatur
    - Erkenntnisse über Nutzerakzeptanz, Nutzerverhalten, Technologieentwicklung und neuartige
- Sicherheitskonzepte
    - Erhebung und Dokumentation von Nutzeranforderungen
    - Erkenntnisse aus bestehenden und neuen Systemen gewinnen und in Anforderungen einfließen lassen
- Gesetzliche Vorgaben, Normen und organisatorischer Kontext
    - Vorgaben der Organisation
    - Gesetzliche Vorgaben und Normen
- Weitere Datenquelle: Nutzer- und Nutzungsstudien
::: warning Kommentar
Quasi wie Kontext-, Aufgaben-, Organisations- und Nutzeranalyse.
:::

#### Risikoidentifikation
::: tip Risikoidentifikation
- Risiken identifizieren
- Ursachen und Auswirkung beurteilen
:::

#### Risikoanalyse
::: tip Risikoanalyse
- Analyse möglicher Konsequenzen und deren Wahrscheinlichkeit
- Hilft, Kosten und Risiken im Vorfeld abzuwiegen
:::

### Design & Entwicklung
#### Mensch und Maschine integrieren
| Menschen können gut | Maschinen können gut |
| -  | - |
| Ziele setzen | Schnell Daten verarbeiten |
| Teilprobleme definieren | Aktivitäten fehlerfrei wiederholen |
| Ganzheitliche Wahrnehmung nutzen | Differenziale und Integrale bilden |
| Entscheidungen durchführen | Inkonsistenzen erkennen |
| Verantwortung tragen | Langfristig ermüdungsfrei arbeiten |

::: warning Kommentar
Erinnert an MABA-MABA.
:::

Mensch und Maschine dürfen nicht getrennt von einander betrachten werden, sondern als zusammengehörige Glieder. Die Arbeitsteilung muss für beide Parteien klar definiert werden, da sonst die Gefahr besteht, dass die Mensch-Maschine-Schnittstelle zur Ursache von Fehlern und Schäden wird.
::: warning Kommentar
Deshalb wird die Arbeit wohl so aufgeteilt, sodass jeder das macht was er am besten kann. Ist das aber immer sinnvoll?
:::

::: tip Verantwortliches Systemdesign
Das Konzept des verantwortlichen Systemdesigns zielt darauf ab, in der Arbeitsteilung zwischen Mensch und Maschine eine derartige Rollenverteilung zu schaffen, die einerseits beiden Komponenten genau definierte Handlungsspielräume aufzeigt, diese andererseits kongruent aufeinander aufbauen lässt.“ [(Herczeg, 2014)](/references/#herczeg-m-2014)
:::

#### Ausnahmen
Man darf nicht hoffen das alles gut wird. Selbst ein kleiner Fehler kann zu einem Schneeballeffekt führen. In anderen Worten kann die Anhäufung von kleinen Fehlern zu einer Katastrophe führen. Das Schweizer-Käse-Modell beschreibt dies ungefähr: Das Ideal ist eine Reihe von Barrieren vor den Gefahren. In der Realität haben diese Barrieren jedoch Löcher. Deshalb sollte man auch die Ausnahmen möglichst klein halten und mehrstufig abschotten. 

![cheese](/assets/cheese.png)

#### Design for Error
Das Ziel ist die Gestaltung eines Systems, welches die Sicherheit des gesamten System weiterhin sicherstellt, trotz ausgelöster Fehlhandlungen durch den Nutzer. Dazu werden alle möglichen Fehler berücksichtigt (menschlich, technisch, interaktionsbezogen), komplementäre Redundanzen zwischen Mensch und Maschine geschaffen und die Fehlertoleranz betrachtet.

::: danger Unklar
Komplementäre Redundanzen wozu? Zur Gegenseitigen Doppelkontrolle?
:::

#### Usability über User Experience
> Effektivität und Effizienz sind oft wichtiger als die Erfüllung von
Benutzerpräferenzen [(ISO 9241-210, 2011)](/references/#iso-9241-210-2011)

::: warning Kommentar
Es ist nicht schön, aber es erledigt seinen Job. Ergebnis vor Erlebnis.
:::

#### Sicherere Dialoge gestalten (Dialogkriterien)
::: tip Dialogkriterien
- aufgabenangemessen
- selbstbeschreibungsfähig
- erwartungskonform
- lernförderlich
- steuerbar
- fehlertolerant
- Individualisierbar
:::

### Evaluation
#### Nutzen evaluieren (nicht ausprobieren)
Man muss summativ und formativ evaluieren. Jedoch lässt sich nicht alles evaluieren (Fehler in Kraftwerksteuerung ausprobieren). Deshalb ist der Einsatz von Experten oder Modellen geraten. Zu den möglichen Evaluationkriterien zählen hierbei:
- Funktionalität
- Leistung
- Vollständigkeit
- Konsistenz
- Genauigkeit
- Verlässlichkeit
- Gebrauchstauglichkeit
- Organisationale Passung

#### Verbesserungskultur etablieren
Nach der Evaluation schauen, ob der Soll-Zustand erreicht wurde. Vielleicht wurden neue Probleme aufgedeckt oder neue Ziele festgelegt. Das System sollte deshalb iterativ verbessert werden.



## Aufgaben

### 1. Literaturrecherche

#### a) Finden Sie eine Publikation, in welcher eine Risikoanalyse für ein sicherheitskritisches System durchgeführt wird oder welche das Vorgehen bei der Risikoanalyse sicherheitskritischer Systeme untersucht.

```
https://www.faa.gov/news/safety_briefing/2016/media/SE_Topic_16-12.pdf
```

#### b) Beschreiben Sie in Ihren eigenen Worten, wie bei der Identifikation und Bewertung der Risiken vorgegangen wurde.

```
Flight Risk Assessment Tools (FRAT) sind Fragebögen, die das Risiko für eine Gefahr 
für ein Flug vor dem eigentlichen Start einschätzen. Dabei bestehen die Fragen aus 
typischen Gefahren die Piloten regelmäßig entgegenkommen. Eine Version orientiert sich 
zur Identifikation von Risiken an die PAVE Checkliste (Pilot, Aircraft, Environment, 
External Pressures). Dabei handelt es sich um Fragen wie z.B. das Wetter gerade ist 
und wie das Befinden des Piloten ist. Am Ende wird ein Score aus den beantworteten 
Fragen berechnet. Aus dem Score kann dann abgelesen werden, in welcher Risikokategorie 
man sich dann befindet: 

- Grün (low): fliegen
- gelb (medium): versuchen einen besseren Score zu bekommen durch abschwächen von 
Risiken (z.B. warten bis das Wetter gut wird)
- rot (high): nicht fliegen, Flug abbrechen
```

### 2. Grundsätze der Dialoggestaltung

#### a) Nennen Sie jeweils ein praktisches Beispiel für die Anwendung der Kriterien bei der Konzeption eines sicherheitskritischen Systems. 

```
- aufgabenangemessen: Eindeutige Grafiken, die bei der Aufgabe helfen.
- selbstbeschreibungsfähig: Warnungen bei einem instabilen Systemzustand.
- erwartungskonform: Affordanzen/Mappings
- lernförderlich: Handbücher, Simulatoren
- steuerbar: Ausschalten eines Autopiloten z.B. beim Autofahren
- fehlertolerant: KI erkennt fehler und warnt zur bevorstehenden Handlung
- Individualisierbar: Sitzeinstellung im Flugzeugcockpit
```

